% ============================================================================
% INDUSTRY FOCUS REFERENCES
% ============================================================================
% Bibliography for practical industry ML content:
% - MLOps and Model Deployment
% - Data Quality and Monitoring
% - Business Stakeholder Communication
% - Regulatory Compliance and Ethics
%
% Author: Diogo Ribeiro
% Last Updated: January 5, 2025
% ============================================================================

% ============================================================================
% MLOPS AND MODEL DEPLOYMENT
% ============================================================================

@article{sculley2015hidden,
  title={Hidden technical debt in machine learning systems},
  author={Sculley, David and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Fran{\c{c}}ois and Dennison, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015},
  pages={2503--2511},
  note={Seminal paper on ML technical debt from Google}
}

@techreport{google2021mlops,
  title={{MLOps}: Continuous delivery and automation pipelines in machine learning},
  author={Google Cloud},
  institution={Google},
  year={2021},
  url={https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning},
  note={Industry best practices for MLOps maturity}
}

@article{venturebeat2019,
  title={Why do 87\% of data science projects never make it into production?},
  author={VentureBeat},
  journal={VentureBeat},
  year={2019},
  url={https://venturebeat.com/ai/why-do-87-of-data-science-projects-never-make-it-into-production/}
}

@inproceedings{breck2017ml,
  title={The {ML} test score: A rubric for {ML} production readiness and technical debt reduction},
  author={Breck, Eric and Cai, Shanqing and Nielsen, Eric and Salib, Michael and Sculley, D},
  booktitle={IEEE International Conference on Big Data},
  pages={1123--1132},
  year={2017},
  organization={IEEE}
}

@article{polyzotis2017data,
  title={Data management challenges in production machine learning},
  author={Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
  journal={Proceedings of the 2017 ACM International Conference on Management of Data},
  pages={1723--1726},
  year={2017}
}

@inproceedings{mcmahan2017fedavg,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{vartak2016modeldb,
  title={{ModelDB}: a system for machine learning model management},
  author={Vartak, Manasi and Subramanyam, Harihar and Lee, Wei-En and Viswanathan, Srinidhi and Husnoo, Saadiyah and Madden, Samuel and Zaharia, Matei},
  journal={Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
  pages={1--3},
  year={2016}
}

@inproceedings{chen2020developments,
  title={Developments in {MLflow}: A system to accelerate the machine learning lifecycle},
  author={Chen, Andrew and Chow, Andy and Davidson, Aaron and DCunha, Arjun and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Mewald, Clemens and Murching, Siddharth and Nykodym, Tomas and others},
  booktitle={Proceedings of the Fourth International Workshop on Data Management for End-to-End Machine Learning},
  pages={1--4},
  year={2020}
}

@inproceedings{baylor2017tfx,
  title={{TFX}: A {TensorFlow}-based production-scale machine learning platform},
  author={Baylor, Denis and Breck, Eric and Cheng, Heng-Tze and Fiedel, Noah and Foo, Chuan Yu and Haque, Zakaria and Haykal, Salem and Ispir, Mustafa and Jain, Vihan and Koc, Levent and others},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1387--1395},
  year={2017}
}

@article{renggli2021data,
  title={A data quality-driven view of {MLOps}},
  author={Renggli, Cedric and Karla{\v{s}}, Bojan and Ding, Bolin and Liu, Feng and Schawinski, Kevin and Wu, Wentao and Zhang, Ce},
  journal={IEEE Data Engineering Bulletin},
  volume={44},
  number={1},
  pages={11--23},
  year={2021}
}

@inproceedings{paleyes2022challenges,
  title={Challenges in deploying machine learning: a survey of case studies},
  author={Paleyes, Andrei and Urma, Raoul-Gabriel and Lawrence, Neil D},
  journal={ACM Computing Surveys},
  volume={55},
  number={6},
  pages={1--29},
  year={2022},
  publisher={ACM New York, NY}
}

% ============================================================================
% DATA QUALITY AND MONITORING
% ============================================================================

@inproceedings{schelter2018automating,
  title={Automating large-scale data quality verification},
  author={Schelter, Sebastian and Lange, Dustin and Schmidt, Philipp and Celikel, Meltem and Biessmann, Felix and Grafberger, Andreas},
  booktitle={Proceedings of the VLDB Endowment},
  volume={11},
  number={12},
  pages={1781--1794},
  year={2018}
}

@article{gama2014survey,
  title={A survey on concept drift adaptation},
  author={Gama, Jo{\~a}o and {\v{Z}}liobait{\.e}, Indr{\.e} and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
  journal={ACM Computing Surveys},
  volume={46},
  number={4},
  pages={1--37},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@inproceedings{rabanser2019failing,
  title={Failing loudly: An empirical study of methods for detecting dataset shift},
  author={Rabanser, Stephan and G{\"u}nnemann, Stephan and Lipton, Zachary},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{lu2018learning,
  title={Learning under concept drift: A review},
  author={Lu, Jie and Liu, Anjin and Dong, Fan and Gu, Feng and Gama, Joao and Zhang, Guangquan},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={31},
  number={12},
  pages={2346--2363},
  year={2018},
  publisher={IEEE}
}

@inproceedings{arrieta2020explainable,
  title={Explainable Artificial Intelligence ({XAI}): Concepts, taxonomies, opportunities and challenges toward responsible {AI}},
  author={Arrieta, Alejandro Barredo and D{\'\i}az-Rodr{\'\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\'\i}a, Salvador and Gil-L{\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  journal={Information Fusion},
  volume={58},
  pages={82--115},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={25},
  pages={723--773},
  year={2012}
}

@article{bifet2009learning,
  title={Learning from time-changing data with adaptive windowing},
  author={Bifet, Albert and Gavald{\`a}, Ricard},
  journal={Proceedings of the 2007 SIAM International Conference on Data Mining},
  pages={443--448},
  year={2009},
  publisher={SIAM}
}

@misc{greatexpectations,
  title={{Great Expectations}: Always know what to expect from your data},
  author={{Great Expectations}},
  year={2023},
  url={https://greatexpectations.io/},
  note={Open-source data validation framework}
}

@inproceedings{breck2019data,
  title={Data validation for machine learning},
  author={Breck, Eric and Polyzotis, Neoklis and Roy, Sudip and Whang, Steven and Zinkevich, Martin},
  booktitle={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={334--347},
  year={2019}
}

@article{hynes2017data,
  title={The data linter: Lightweight, automated sanity checking for {ML} data sets},
  author={Hynes, Nick and Sculley, D and Terry, Michael},
  journal={NIPS MLSys Workshop},
  year={2017}
}

% ============================================================================
% BUSINESS STAKEHOLDER COMMUNICATION
% ============================================================================

@book{provost2013data,
  title={Data Science for Business: What you need to know about data mining and data-analytic thinking},
  author={Provost, Foster and Fawcett, Tom},
  year={2013},
  publisher={O'Reilly Media},
  note={Essential reading for translating ML to business value}
}

@article{davenport2012data,
  title={Data scientist: The sexiest job of the 21st century},
  author={Davenport, Thomas H and Patil, DJ},
  journal={Harvard Business Review},
  volume={90},
  number={10},
  pages={70--76},
  year={2012}
}

@book{patil2015building,
  title={Building Data Science Teams},
  author={Patil, DJ},
  year={2015},
  publisher={O'Reilly Media},
  note={Insights on data science team structure and communication}
}

@article{ransbotham2020expanding,
  title={Expanding {AI's} Impact with Organizational Learning},
  author={Ransbotham, Sam and Khodabandeh, Shervin and Kiron, David and Candelon, Fran{\c{c}}ois and Chu, Michael and LaFountain, Burt},
  journal={MIT Sloan Management Review and Boston Consulting Group},
  year={2020}
}

@book{hubbard2014measure,
  title={How to measure anything: Finding the value of intangibles in business},
  author={Hubbard, Douglas W},
  year={2014},
  publisher={John Wiley \& Sons},
  edition={3rd},
  note={Quantifying business value of ML projects}
}

@article{agrawal2018prediction,
  title={Prediction machines: the simple economics of artificial intelligence},
  author={Agrawal, Ajay and Gans, Joshua and Goldfarb, Avi},
  year={2018},
  publisher={Harvard Business Press},
  note={Economic framing of ML for business leaders}
}

@article{brynjolfsson2017business,
  title={The business of artificial intelligence},
  author={Brynjolfsson, Erik and Mitchell, Tom},
  journal={Harvard Business Review},
  year={2017},
  note={Strategic considerations for AI adoption}
}

% ============================================================================
% REGULATORY COMPLIANCE AND ETHICS
% ============================================================================

@article{eu2024aiact,
  title={{EU Artificial Intelligence Act}},
  author={{European Parliament and Council}},
  journal={Official Journal of the European Union},
  year={2024},
  note={Comprehensive AI regulation framework}
}

@article{gdpr2016,
  title={{General Data Protection Regulation (GDPR)}},
  author={{European Parliament and Council}},
  journal={Official Journal of the European Union},
  volume={L119},
  pages={1--88},
  year={2016},
  note={EU data protection and privacy regulation}
}

@article{wachter2017right,
  title={Why a right to explanation of automated decision-making does not exist in the general data protection regulation},
  author={Wachter, Sandra and Mittelstadt, Brent and Floridi, Luciano},
  journal={International Data Privacy Law},
  volume={7},
  number={2},
  pages={76--99},
  year={2017},
  publisher={Oxford University Press}
}

@article{goodman2017european,
  title={European Union regulations on algorithmic decision-making and a "right to explanation"},
  author={Goodman, Bryce and Flaxman, Seth},
  journal={AI Magazine},
  volume={38},
  number={3},
  pages={50--57},
  year={2017}
}

@article{barocas2016big,
  title={Big data's disparate impact},
  author={Barocas, Solon and Selbst, Andrew D},
  journal={California Law Review},
  volume={104},
  pages={671--732},
  year={2016}
}

@article{angwin2016machine,
  title={Machine bias: There's software used across the country to predict future criminals. And it's biased against blacks},
  author={Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  journal={ProPublica},
  year={2016},
  month={May},
  note={Investigative report on COMPAS algorithm bias}
}

@inproceedings{corbett2018measure,
  title={The measure and mismeasure of fairness: A critical review of fair machine learning},
  author={Corbett-Davies, Sam and Goel, Sharad},
  journal={arXiv preprint arXiv:1808.00023},
  year={2018}
}

@inproceedings{mitchell2019model,
  title={Model cards for model reporting},
  author={Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Proceedings of the Conference on Fairness, Accountability, and Transparency},
  pages={220--229},
  year={2019}
}

@article{gebru2021datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{bellamy2018ai,
  title={{AI Fairness 360}: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias},
  author={Bellamy, Rachel KE and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovi{\'c}, Aleksandra and others},
  journal={IBM Journal of Research and Development},
  volume={63},
  number={4/5},
  pages={4--1},
  year={2019},
  organization={IBM}
}

@article{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of Cryptography Conference},
  pages={265--284},
  year={2006},
  organization={Springer}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages={308--318},
  year={2016}
}

@article{jobin2019global,
  title={The global landscape of {AI} ethics guidelines},
  author={Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  journal={Nature Machine Intelligence},
  volume={1},
  number={9},
  pages={389--399},
  year={2019},
  publisher={Nature Publishing Group}
}

@book{oneill2016weapons,
  title={Weapons of math destruction: How big data increases inequality and threatens democracy},
  author={O'Neil, Cathy},
  year={2016},
  publisher={Crown},
  note={Ethical implications of algorithmic decision-making}
}

@article{binns2018fairness,
  title={Fairness in machine learning: Lessons from political philosophy},
  author={Binns, Reuben},
  journal={Proceedings of the 1st Conference on Fairness, Accountability and Transparency},
  pages={149--159},
  year={2018}
}

@article{holstein2019improving,
  title={Improving fairness in machine learning systems: What do industry practitioners need?},
  author={Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum{\'e} III, Hal and Dudik, Miro and Wallach, Hanna},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2019}
}

@techreport{nist2023aiframework,
  title={{AI Risk Management Framework}},
  author={{National Institute of Standards and Technology}},
  institution={NIST},
  year={2023},
  note={US government AI risk framework}
}

@article{raji2020closing,
  title={Closing the {AI} accountability gap: defining an end-to-end framework for internal algorithmic auditing},
  author={Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca N and Mitchell, Margaret and Gebru, Timnit and Hutchinson, Ben and Smith-Loud, Jamila and Theron, Daniel and Barnes, Parker},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={33--44},
  year={2020}
}

@article{floridi2018ai4people,
  title={{AI4People}â€”an ethical framework for a good {AI} society: opportunities, risks, principles, and recommendations},
  author={Floridi, Luciano and Cowls, Josh and Beltrametti, Monica and Chatila, Raja and Chazerand, Patrice and Dignum, Virginia and Luetge, Christoph and Madelin, Robert and Pagallo, Ugo and Rossi, Francesca and others},
  journal={Minds and Machines},
  volume={28},
  number={4},
  pages={689--707},
  year={2018},
  publisher={Springer}
}

@article{lehr2017playing,
  title={Playing with the data: What legal scholars should learn about machine learning},
  author={Lehr, David and Ohm, Paul},
  journal={UC Davis Law Review},
  volume={51},
  pages={653},
  year={2017}
}

@inproceedings{ribeiro2016lime,
  title={"Why should I trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1135--1144},
  year={2016}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{chouldechova2017fair,
  title={Fair prediction with disparate impact: A study of bias in recidivism prediction instruments},
  author={Chouldechova, Alexandra},
  journal={Big Data},
  volume={5},
  number={2},
  pages={153--163},
  year={2017},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@article{kleinberg2016inherent,
  title={Inherent trade-offs in the fair determination of risk scores},
  author={Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  journal={arXiv preprint arXiv:1609.05807},
  year={2016}
}

% ============================================================================
% INDUSTRY CASE STUDIES AND APPLICATIONS
% ============================================================================

@article{amazon2018recruiting,
  title={Amazon scraps secret {AI} recruiting tool that showed bias against women},
  author={Dastin, Jeffrey},
  journal={Reuters},
  year={2018},
  note={Case study on algorithmic bias in hiring}
}

@article{knight2012capital,
  title={Knight Capital glitch loss hits \$440 million},
  author={Popper, Nathaniel},
  journal={The New York Times},
  year={2012},
  note={Case study on deployment failures}
}

@article{netflix2012prize,
  title={The {Netflix Prize} and privacy},
  author={Narayanan, Arvind and Shmatikov, Vitaly},
  journal={Communications of the ACM},
  volume={53},
  number={12},
  pages={143--143},
  year={2010},
  publisher={ACM New York, NY, USA}
}

@techreport{mckinsey2020ai,
  title={The state of {AI} in 2020},
  author={{McKinsey \& Company}},
  year={2020},
  institution={McKinsey Global Institute},
  note={Industry survey on AI adoption challenges}
}

% ============================================================================
% TOOLS AND FRAMEWORKS
% ============================================================================

@misc{kubeflow,
  title={{Kubeflow}: The machine learning toolkit for {Kubernetes}},
  author={{Kubeflow Community}},
  year={2023},
  url={https://www.kubeflow.org/}
}

@misc{feast,
  title={{Feast}: Feature store for machine learning},
  author={{Feast Community}},
  year={2023},
  url={https://feast.dev/}
}

@misc{tensorflowprivacy,
  title={{TensorFlow Privacy}: Library for training machine learning models with privacy},
  author={{TensorFlow Authors}},
  year={2023},
  url={https://github.com/tensorflow/privacy}
}

@misc{aif360,
  title={{AI Fairness 360}: An open source toolkit for bias detection and mitigation},
  author={IBM Research},
  year={2023},
  url={https://aif360.mybluemix.net/}
}

@misc{fairlearn,
  title={{Fairlearn}: A toolkit for assessing and improving fairness in {AI}},
  author={Microsoft Research},
  year={2023},
  url={https://fairlearn.org/}
}

% ============================================================================
% END OF REFERENCES
% ============================================================================
